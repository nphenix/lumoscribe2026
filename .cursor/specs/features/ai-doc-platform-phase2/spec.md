---
id: ai-doc-platform-phase2
status: DRAFT
created: 2026-01-29
updated: 2026-01-29
links:
  - ./plan.md
  - ./tasks.md
---

# 功能规格说明：第二阶段 AI 文档生成平台

|**功能分支**: `feature/phase2-ai-doc-platform`  
|**创建日期**: 2026-01-29  
|**状态**: 草稿  
|**输入**: "在第一阶段 ingest + 建库 + 单 HTML 生成平台的基础上，系统性提升报告生成质量与可视化能力，包括：重构 Html 生成链路、基于 AntV 重构数据可视化模块，以及增强中台对 LLM 并发与提示词的配置与治理能力。"

---

## 用户场景与测试

### 用户故事 1 - 提升报告 Html 生成质量（P1）

面向市场研究/政策研究分析师，用户在中台选择知识库、模板和大纲后，一键生成长篇 Html 报告。与第一阶段相比，新链路要求：

- 严格按照大纲与模板结构输出，每个 h2/h3 标题下必须有严谨、充分的正文内容；
- 显著降低跨章节的内容重复，避免同一事实在多个小节反复出现；
- 图表仅以占位符形式出现在正文中，位置稳定、不会被 LLM 改写或漂移。

|**为何是该优先级**: 直接决定白皮书/行业报告的交付质量，是第二阶段的核心目标。  
|**独立测试**: 使用同一知识库和模板多次生成报告，对比重复率、章节完整性和图表占位符位置，验证新链路的稳定性与改进幅度。  

**验收场景**:

1. 假设使用指定模板和大纲生成报告，当比较不同章节时，则相同事实不会在多个章节大段重复出现。
2. 假设模板大纲中存在所有 h2/h3 小节，当生成报告时，则每个小节都包含充分正文且无“只有标题/纲要条目”的空壳章节。
3. 假设正文中仅使用 `[Chart:id]` 这类锚点，当生成 Html 时，则所有图表只在对应锚点位置渲染，不会重复或漂移到其他段落。
4. 假设对同一输入多次生成 Html，当对比结果时，则文档结构与图表布局保持一致，仅允许措辞级别的微小差异。

---

### 用户故事 2 - 统一、专业的图表与信息图呈现（P1）

分析师希望报告中的统计图、信息图和逻辑图具有统一的视觉风格，贴近“专业科研/智库报告”审美，而非营销海报风。系统需要：

- 基于图表 JSON（chart_json）与原图（images），使用统一的 AntV 技术栈（G2、InfoGraphic、S2）渲染统计图、信息图和分析型表格；
- 支持 SVG/PNG 导出，方便插入 Html、PDF 导出和打印；
- 支持定义“白皮书主题”，统一颜色、字体、线条风格，保证同一份 Html 内视觉一致。

|**为何是该优先级**: 图表与信息图是报告说服力的关键组成部分，统一、专业的视觉风格是第二阶段的重要交付。  
|**独立测试**: 针对 sankey、stacked_area、table 等典型 chart_json，生成对应的图表/信息图，检查视觉风格是否一致、是否符合预期的科研风格。  

**验收场景**:

1. 假设提供 sankey 类型的 chart_json，当通过可视化模块渲染后，则输出的图能够清晰表达价值流转逻辑，风格与其他图表一致。
2. 假设提供 stacked_area 类型的 chart_json，当渲染为堆叠面积图时，则坐标轴、图例和配色符合“白皮书主题”，且支持导出 SVG/PNG。
3. 假设提供 table 类型的 chart_json，当选择“信息图模式”渲染时，则生成时间线或清单式信息图，而非简单 HTML 表格，风格与整份报告一致。
4. 假设同一份报告中包含多个图表与信息图，当整体预览时，则所有图形元素在配色、字体和线条风格上保持统一。

---

### 用户故事 3 - 中台可控的 LLM 并发与提示词管理（P1）

中台运维人员希望通过 Web 界面统一管理 LLM Provider 的参数、并发限制和提示词版本，而无需修改代码。第二阶段需要：

- 在中台 Provider/CallSite 配置界面增加“最大并发数”等关键字段，限制文档清洗、图转 JSON、内容生成等各阶段对各 Provider 的并发调用；
- 在中台 Prompt 管理界面支持查看、编辑、版本化和灰度启用提示词，避免在代码中硬编码 Prompt；
- 所有 LLM 调用点统一通过 LLMRuntimeService 和 CallSite 读取这些配置。

|**为何是该优先级**: 控制 LLM 成本与稳定性，降低工程运维风险，同时为第二阶段内容与可视化能力提供可靠基础。  
|**独立测试**: 在中台调整某个 Provider 的最大并发配置和 Prompt 版本后，观察文档清洗/生成任务的行为与日志，验证配置是否生效。  

**验收场景**:

1. 假设在中台将某 Provider 的最大并发行数设置为 N，当同时触发超过 N 个依赖该 Provider 的任务时，则系统不会超过该并发上限。
2. 假设在 Prompt 管理界面新建一个版本并设为激活，当再次触发对应 CallSite 的 LLM 调用时，则日志中使用的是新版本 Prompt。
3. 假设关闭某个 Prompt 版本或 Provider，当触发依赖其的功能时，则系统给出清晰错误提示而不是静默失败。

---

### 用户故事 4 - 可插拔的后处理与 QA 能力（P2）

先进用户或内部算法团队希望在报告生成后插入自定义后处理步骤，例如：语义去重、章节结构校验、语言润色等。系统需要：

- 在 Html 生成链路中划分清晰的阶段边界（生成草稿 → 结构和重复检查 → 语言润色），为后续扩展 QA 插件留出挂载点；
- 优先实现一套内置的“语义去重 + 空章节检测”能力，使用现有向量存储/检索基础设施；
- 支持在中台配置是否启用某些后处理步骤。

|**为何是该优先级**: 虽然不是第二阶段的 MVP，但为持续提升报告质量提供可扩展空间。  
|**独立测试**: 打开/关闭去重与空章节检测功能，对比生成 Html 前后的重复率和结构完整性。  

**验收场景**:

1. 假设启用语义去重后，当生成报告时，则跨章节重复段落显著减少，且不会删除本就较薄弱的章节内容。
2. 假设启用空章节检测后，当生成报告时，则不会再出现“只有标题或纲要条目、无正文”的小节。
3. 假设在中台关闭某个后处理步骤，当再次生成报告时，则该步骤不再生效且日志中有清晰记录。

---

## 需求

### 功能性需求

- **FR-201**: 系统必须将 Html 生成链路拆分为明确阶段（按章节生成草稿 → 语义去重/结构校验 → 语言润色），并保证每个阶段的输入/输出可观测、可调试。
- **FR-202**: 系统必须在章节级生成中严格遵守大纲和模板结构，保证所有大纲中的 h2/h3 小节都有对应正文内容，不得自动省略或合并小节。
- **FR-203**: 系统必须通过统一的图表占位符（例如 `[Chart:id]`）在正文中标注图表位置，不得让 LLM 直接输出具体图表 HTML。
- **FR-204**: 系统必须基于图表 JSON 和原图，引入 AntV 技术栈（G2、InfoGraphic、S2）重构“图表 JSON → 可视化图形”的能力，支持统计图、信息图和分析型表格。
- **FR-205**: 系统必须支持可视化结果导出为 SVG/PNG，并可嵌入到 Html 报告或用于 PDF/打印。
- **FR-206**: 系统必须提供统一的“白皮书主题”配置，用于控制图表和信息图的颜色、字体、线条风格等视觉要素，并在所有可视化输出中保持一致。
- **FR-207**: 系统必须在中台 Provider/CallSite 配置界面支持配置 LLM 并发相关参数（如最大并发数），并在运行时由 LLMRuntimeService 和相关服务遵守该限制。
- **FR-208**: 系统必须在中台 Prompt 管理界面支持提示词的查看、编辑、版本化与启用/停用，并保证所有业务调用点只通过 PromptService/LLMRuntimeService 访问 Prompt。
- **FR-209**: 系统必须在 Html 生成流程中预留可插拔的后处理阶段，至少包含基于向量检索的语义去重与空章节检测能力，并支持在中台配置启用状态。

### 关键实体（第二阶段新增或增强）

- **SectionGenerationPipeline**: 章节级生成管线配置，包含阶段划分、启用的后处理步骤和相关参数。
- **ChartRenderConfig**: 图表渲染配置，包含使用的引擎（G2/InfoGraphic/S2）、主题标识、导出格式和尺寸等。
- **VisualizationTheme**: 可视化主题实体，定义白皮书主题的配色、字体和线条风格。
- **LLMConcurrencyPolicy**: LLM 并发策略配置，按 Provider/CallSite 维度控制最大并发等参数。
- **PromptVersion**: 提示词版本实体，记录 scope、内容、版本号、启用状态和变更说明。
- **PostProcessingRule**: 报告后处理规则实体，描述语义去重、结构校验等步骤的启用情况和阈值参数。

---

## API 与集成范围（增量要求）

> 第二阶段不强制新增大量对外 REST API，更关注对现有 `/v1/jobs`、`/v1/targets`、中台配置 API 的增强与扩展。具体接口细节在 plan.md 中进一步细化。

### 与现有接口的关系

- 生成目标 Html 的 API 仍使用第一阶段定义的 `/v1/jobs` + `/v1/targets` 组合，但其内部实现将切换为新的 Html 生成管线和可视化模块。
- LLM Provider/CallSite/Prompt 相关 API 复用第一阶段定义的 `/v1/llm/*` 路由，仅在请求/响应结构中增加并发与版本化相关字段。
- 如需新增可视化预览或导出 API，将在 plan.md 中补充具体端点与请求/响应示例。

---

**版本**: 1.0.0 | **创建**: 2026-01-29

